# Assignment 6: Analysis of longitudinal data

In this final week, I have worked on analysis of longitudinal data. I think throughout these 6 weeks, I grew accustomed to R as much as I can for the time being. For now, I will take a break from R and focus on other tasks :) It was a perfect course for me, even though I feel like I may not have learned what I should have learned.

```{r}
date()
```
## 4.1: Data wrangling

Data wrangling part of this week was a short but important task. The R code of the data wrangling part is in the data folder of my Github repository. I will put the link here as well: https://github.com/bbayraktaroglu/IODS-project/blob/master/data/meet_and_repeat.R


## 4.2: Analysis 

### Setting up the packages
```{r, warning=FALSE, message =FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(tidyr)
library(lme4)
```



### 4.2.1: Reading the dataset for all of the assignment
```{r}
# set working directory
setwd("~/Github/IODS-project")

# reading the required files for the assignment
RATS <- read_csv("data/RATS.csv")
BPRS <- read_csv("data/BPRS.csv")
```

We now convert both of the data to long format:
```{r}
# convert the categorical variables of both data sets to factors

BPRS$treatment <- factor(BPRS$treatment)
BPRS$subject <- factor(BPRS$subject)

RATS$ID <- factor(RATS$ID)
RATS$Group <- factor(RATS$Group)

# convert the data sets to long form, add a week variable to BPRS and a time variable to RATS

BPRSL <-  pivot_longer(BPRS, cols=-c(treatment,subject),names_to = "weeks",values_to = "bprs") %>% arrange(weeks)
BPRSL <-  BPRSL %>% mutate(week = as.integer(substr(weeks,5,5)))
rm(BPRS)

RATSL <- pivot_longer(RATS, cols=-c(ID,Group), names_to = "WD",values_to = "Weight")  %>%  mutate(Time = as.integer(substr(WD,3,4))) %>% arrange(Time)
```


### 4.2.2: Part 1: RATS

We start with the longitudinal analysis for the dataset 'RATS'.

```{r}
# checking the columns of the long data
colnames(RATSL)

# dimensions of the long data
dim(RATSL)

# structure of the long data
str(RATSL)

# summaries of the long data
summary(RATSL)
```

The 'RATS' data was obtained as a nutritional study on three groups of rats (16 rats in total), where each of them were put under a different type of diet. Throughout several weeks, their weights (with unit in grams) were recorded. The aim was to see how different type of diet affect the weight of rats.

We see that there are 176 observations and 5 variables in the long format data. The variables are: 

* ID (identification of the rat; factor variable between 1-16) 
* Group (group of the rat; factor variable between 1-3)
* WD (which day the measurement took place; character with 11 different values)
* Weight (weight of the rat in grams; numeric)
* Time (day of the measurement; integer with 11 different values)

### 4.2.2.1 Plots

```{r}
# Plot the RATSL data
ggplot(RATSL, aes(x = Time, y = Weight, linetype = ID)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(RATSL$Weight), max(RATSL$Weight))) 

```

Observe that rats in Group 1 and Group 3 have quite close weights within each group, while there is an obvious outlier in Group 2. On average, the Group 1 rats have the lowest weight, while on average the Group 3 rats have the highest weight. The outlier rat in Group 2 has the most weight out of all the rats. Moreover, as time passes on, there is an overall increase of weight for individual rats.


### 4.2.2.2 Standardization of variables

```{r}
# standardize the variable
RATSL<-RATSL %>%
  group_by(Group) %>%
  mutate(stdWeight = (Weight-mean(Weight))/sd(Weight)) %>%
  ungroup()
# Glimpse the data
glimpse(BPRSL)

# Plot again with the standardised RATSL
ggplot(RATSL, aes(x = Time, y = stdWeight, linetype = ID)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  scale_y_continuous(name = "standardized RATS weight")

```

Now, after standardization of the RATS data, we can finally see explicit changes in the data and compare the different groups more clearly. Of course we need to do further analysis to come up with an interpretation of what's going on.

### 4.2.2.3 Summary graph

```{r}
# Number of rats:
n <- 16


# Summary data with mean and standard error of Weight by Group and Time 
RATSS <- RATSL %>%
  group_by(Group, Time) %>%
  summarise( mean = mean(Weight), se = sd(Weight)/sqrt(n) ) %>%
  ungroup()

# Plot the mean profiles
ggplot(RATSS, aes(x = Time, y = mean, linetype = Group, shape = Group)) +
  geom_line() +
  scale_linetype_manual(values = c(1,2,3)) +
  geom_point(size=3) +
  scale_shape_manual(values = c(1,2,3)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3) +
  theme(legend.position = c(0.8,0.8)) +
  scale_y_continuous(name = "mean(Weight) +/- se(Weight)")

```


Now, we can see in the plot above that there is an overall (on average) increase in weight within each group over time. Group 2 has observed the most amount of increase in weight when we compare the initial and the final weights, while Group 2 saw the least amount of increase.


### 4.2.2.4 Finding the outlier(s)

```{r}
# Create a summary data by Group and ID with mean as the summary variable (ignoring baseline Time 0).
RATSL8S <- RATSL %>%
  filter(Time > 0) %>%
  group_by(Group, ID) %>%
  summarise( mean=mean(Weight) ) %>%
  ungroup()

# Draw a boxplot of the mean versus Group
ggplot(RATSL8S, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight), Time 1-64")

```

We see from the boxplot above that all of the groups have a single outlier. Group 2 has an outlier well above the mean of its other data points, while Group 1 and 3 each have an outlier below the mean of their data points. Group 1 seems to have a symmetric distribution, while Group 2 has a highly skewed distribution, with its longer tail concentrated towards below its mean (i.e. it is left skewed). Note that its median is towards the longer tail. Group 3 also has a tiny bit of skewness in its distribution, with its longer tail towards higher values than its mean.


### 4.2.2.5 Removing the outlier(s)

```{r}
# Create a new data by filtering the outlier and adjust the ggplot code, then draw the plot again with the new data
RATSL8S1 <- filter(RATSL8S, (Group==1 & mean>250) | (Group==2 & mean < 590) | (Group==3 & mean>500))
# note how we ignore the corresponding outliers for each group

ggplot(RATSL8S1, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight), Time 1-64")

```

We can see from the boxplots above that we have successfully removed the outliers. Note that the distribution of each of the groups have changed (in some significantly) as can be seen in the new boxplots. Especially, Group 2 has lost most of its skewness and Group 3 has lost all of its skewness. Group 1 unfortunately gained some skewness towards high values, but this gain is too small to be of importance.

### 4.2.2.6 Anova test

Note that we have 3 groups, so we cannot do a t-test for the RATS data (we need to have 2 groups like in BPRS data to be able to perform a t-test). We will just do Anova test.
```{r}
# Add the baseline from the original data as a new variable to the summary data
RATSL8S2 <- RATSL8S %>%
  mutate(baseline = RATS$WD1)

# Fit the linear model with the mean as the response 
fit <- lm(mean ~ baseline+ Group, data = RATSL8S2)

# Compute the analysis of variance table for the fitted model with anova()
anova(fit)

```


We see that the baseline value is highly significant, with a p-value of about $5*10^{-15}$. This implies that the initial weight of the rats have a significant effect on the increase in weight of the rats. But, Group variable is not so significant, with a p-value of about $0.07586$, which is greater than $0.05$. This imples that we cannot reject the null hypothesis, which is in this case was the fact that different groups should have different weights, i.e. that different type of diets have an effect on the increase in weight of the rats. 



### 4.2.3: Part 2: BPRS

We continue with the longitudinal analysis for the dataset 'BPRS'. Note that we have already loaded the data, and made it into long format, which was saved as 'BPRSL'.

```{r}
# checking the columns of the long data
colnames(BPRSL)

# dimensions of the long data
dim(BPRSL)

# structure of the long data
str(BPRSL)

# summaries of the long data
summary(BPRSL)
```

The 'BPRS' data was obtained from 40 male subjects who were randomly assigned into  one of two separate treatment groups. Each subject was rated on the brief psychriatric rating scale (BPRS) measured before treatment began (week 0) and then at weekly intervals for eight weeks. The BPRS assesses several symptoms such as hostility, suspiciousness, hallucinations and grandiosity; each of these is rated from one (not present) to seven (extremely severe). The scale is used to evaluate patients suspected of having schizophrenia.

The long format data 'BPRSL' contains 360 observations and 5 variables. The variables are: 

* treatment (type of treatment given to the subject; factor variable between 1-2) 
* subject (identification of the subject; factor variable between 1-20)
* weeks (which week the measurement took place; character with 9 different values)
* bprs (BPRS score; numeric)
* week (week of the measurement; integer with values in 0-8)

### 4.2.3.1 Plots

```{r}

# Plot the BPRSL data, note that linetype gave errors since we do not have 'continuous lines', so we used col here. But this is fixed below.

ggplot(BPRSL, aes(x = week, y = bprs, group = subject)) +
  geom_line(aes(col = treatment))+
  scale_y_continuous(name = "BPRS")+
  theme(legend.position = "top")

```


Our naive plot above is a little bit messy. We notice that we can differentiate the 'subject' variable for treatment 1 and for treatment 2 into two separate groups, instead of labeling the same subject for two different treatments. This can be done quite easily:

```{r}
# Mutating the subject variable. We identify the treatment 1 subjects to be from 1-20, and treatment 2 subjects to be from 21-40. 

BPRSL$subject <- as.numeric(BPRSL$subject)
BPRSL <- mutate(BPRSL, subject = ifelse(treatment == "2", subject+20, subject))
BPRSL$subject <- factor(BPRSL$subject)

# New plot. We can use col here if we want instead of linetype, it does not matter
ggplot(BPRSL, aes(x = week, y = bprs, group = subject)) +
  geom_line(aes(linetype = treatment))+ 
  scale_y_continuous(name = "BPRS")+
  theme(legend.position = "top")
```

There is an overall decreasing trend in the BPRS variable. Treatment 2 seems like it has a lot of variance towards week 8, while treament 1 does not have that much variance.

### 4.2.3.2 Regression analysis

Here we assume independence of measurements in BPRS throughout several weeks to create a regression model.

```{r}
# create a regression model BPRS_reg
BPRS_reg <- lm(bprs~ week + treatment, data=BPRSL)

# print out a summary of the model
summary(BPRS_reg)
```

The output of the regression model indicates that the "week" variable is highly significant, with a p-value less than $2*10^{-16}$. The estimate is about $-2$, which implies that we expect a decrease in BPRS as we increase the week variable. This supports our earlier claim that as the week went on, we observed a decrease in BPRS.

But the treatment variable is not significant at all, with a p-value of about $0.661$. This implies that we must reject the null hypothesis: there is no significant evidence to support the claim that the two types of treatments affect BPRS in a different manner. Both multiple and adjusted R-squared are also quite low, which implies that the variables we chose are not good explanatory variables, which is probably due to treatment variable.

If we repeat the analysis with just the week variable as the explanatory variable:
```{r}
# create a regression model BPRS_reg
BPRS_reg <- lm(bprs~ week, data=BPRSL)

# print out a summary of the model
summary(BPRS_reg)
```
We see that the adjusted R-squared value has increased, which means week is definitely a good explanatory variable, although it is still quite low,

### 4.2.3.3 Random intercept model

Now we do not assume independence of BPRS measurements.

```{r}
# Create a random intercept model
BPRS_ref <- lmer(bprs ~ week + treatment + (1 | subject), data = BPRSL, REML = FALSE)

# Print the summary of the model
summary(BPRS_ref)
```

Random intercept model allows the linear regression fit for each subject to differ in *intercept* from other subjects. We also forgo the independence assumption. Observe that the estimated standard deviation of the "subject" variable is about $9.869$, which is almost one order of magnitude above $1$. This implies that the intercept of each subject varies quite a lot. The estimates of the "week" and "treatment" variables are exactly the same compared to the regression model, but the t-values have changed.



### 4.2.3.4 Random intercept and random slope model

We now create a random intercept and random slope model.
```{r}
# create a random intercept and random slope model
BPRS_ref1 <- lmer(bprs ~ week + treatment + (week | subject), data = BPRSL, REML = FALSE)

# print a summary of the model
summary(BPRS_ref1)

# perform an ANOVA test on the two models
anova(BPRS_ref1, BPRS_ref)

```


Fitting a random intercept and random slope model allows the linear regression fits for each individual to differ in intercept and in slope. Thus, one can account for the differences in each subjects' change profile throughout the weeks. 

Here, we see that the estimate for the "week" variable is similar compared to the previous model, while the estimate for the "treatment" variable has increased by a factor of $3$. Thus, one can finally see that the choice of treatment can have an impact on the BPRS result. But we do not see which treatment works best.

### 4.2.3.5 Anova test

We now compute an anova test, to compare the variances between the two models above:
```{r}
# perform an ANOVA test on the two models
anova(BPRS_ref1, BPRS_ref)

```
We see that the p-value is quite small. One can conclude that "BPRS_ref1", which is the random intercept and random slope model, gives a better fit of our data.


### 4.2.3.6 Model with interaction

```{r}
# create a random intercept and random slope model with the interaction
BPRS_ref2 <- lmer(bprs ~ week + treatment + week*treatment + (week | subject), data = BPRSL, REML = FALSE)

# print a summary of the model
summary(BPRS_ref2)

# perform an ANOVA test on the two models
anova(BPRS_ref2, BPRS_ref1)
```

As was in the Exercise Set 6, we have added an interaction of the form "week x treatment" to the random intercept and random slope model. We compared the interaction model with the previous model using Anova test. One can see that the p-value is about $0.1821$, which is especially large: it is larger than $0.1$, which implies there is not a strong indication that the new model fits the data better. One can conclude that the previous model fits the data better than the interaction model.


### 4.2.3.7 Plotting the fitted values for the best fit

We now plot the fitted values for the random intercept and random slope model, which was the best possible fit obtained from our analysis.
```{r}
# Create a vector of the fitted values
Fitted <- fitted(BPRS_ref1)


# Create a new column fitted to BPRSL
BPRSL <- BPRSL %>% mutate(Fitted)

# draw the plot of BPRSL with the Fitted values of BPRS
ggplot(BPRSL, aes(x = week, y = Fitted, group = subject)) +
  geom_line(aes(linetype = treatment))+
  scale_y_continuous(name = "Fitted BPRS")+
  theme(legend.position = "top")

```

One can see that overall, there is a decreasing trend in BPRS for almost all of the subjects in both of the treatment groups. This seems to imply that both of the treatments mostly alleviate the symptoms of BPRS successfully. But we can still not see which treatment is more effective.
